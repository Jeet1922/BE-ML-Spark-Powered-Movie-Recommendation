{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Java and PySpark\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!pip install -q pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRmury2CqvHe",
        "outputId": "0b453a44-d540-4979-c617-fd9a01100ef5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Set JAVA_HOME environment variable\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ],
      "metadata": {
        "id": "vGo16q6zrGz9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab Spark Example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "xfSEzbOgrG4c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Verify Spark session\n",
        "print(\"Spark Session Initialized\")\n",
        "print(\"Spark Version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiLGH5JcrqDA",
        "outputId": "a71a356f-a7ae-4b4d-c278-a193a7f7b6c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session Initialized\n",
            "Spark Version: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create a sample CSV file\n",
        "sample_data = \"\"\"id,name,department,salary\n",
        "1,Alice,Engineering,70000\n",
        "2,Bob,Sales,50000\n",
        "3,Charlie,HR,45000\n",
        "4,David,Engineering,80000\n",
        "5,Eva,Marketing,60000\n",
        "\"\"\"\n",
        "with open(\"sample.csv\", \"w\") as f:\n",
        "    f.write(sample_data)"
      ],
      "metadata": {
        "id": "te8YzOJ1rqGf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Read CSV using Spark\n",
        "df = spark.read.option(\"header\", \"true\").csv(\"sample.csv\")\n",
        "df.show(5)\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqSsl_rvuVts",
        "outputId": "1c4fcea6-d7ad-47e6-8d27-da46117d8631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+-----------+------+\n",
            "| id|   name| department|salary|\n",
            "+---+-------+-----------+------+\n",
            "|  1|  Alice|Engineering| 70000|\n",
            "|  2|    Bob|      Sales| 50000|\n",
            "|  3|Charlie|         HR| 45000|\n",
            "|  4|  David|Engineering| 80000|\n",
            "|  5|    Eva|  Marketing| 60000|\n",
            "+---+-------+-----------+------+\n",
            "\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3Ô∏è‚É£ Define Data Paths\n",
        "base_path = \"/content\"\n",
        "\n",
        "users_path = f\"{base_path}/users.csv\"\n",
        "movies_path = f\"{base_path}/movies.csv\"\n",
        "ratings_path = f\"{base_path}/ratings.csv\"\n",
        "watch_history_path = f\"{base_path}/watch_history.csv\"\n",
        "search_logs_path = f\"{base_path}/search_logs.csv\""
      ],
      "metadata": {
        "id": "G1gc4F1EuV0j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4Ô∏è‚É£ Load CSVs as Spark DataFrames\n",
        "users_df = spark.read.option(\"header\", True).csv(users_path)\n",
        "movies_df = spark.read.option(\"header\", True).csv(movies_path)\n",
        "ratings_df = spark.read.option(\"header\", True).csv(ratings_path)\n",
        "watch_history_df = spark.read.option(\"header\", True).csv(watch_history_path)\n",
        "search_logs_df = spark.read.option(\"header\", True).csv(search_logs_path)"
      ],
      "metadata": {
        "id": "X59La04E1zV9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5Ô∏è‚É£ Display Sample Records\n",
        "print(\"Users:\")\n",
        "users_df.show(5)\n",
        "\n",
        "print(\"Movies:\")\n",
        "movies_df.show(5)\n",
        "\n",
        "print(\"Ratings:\")\n",
        "ratings_df.show(5)\n",
        "\n",
        "print(\"Watch History:\")\n",
        "watch_history_df.show(5)\n",
        "\n",
        "print(\"Search Logs:\")\n",
        "search_logs_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yftTDtKN2WIu",
        "outputId": "6bfd44ad-a3ad-4bc9-ce77-17eafc9076fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users:\n",
            "+-------+-------+---+---------------+\n",
            "|user_id|   name|age|       location|\n",
            "+-------+-------+---+---------------+\n",
            "|      1|  Kevin| 56|  Nicholsonport|\n",
            "|      2|Cassidy| 46|      Josephton|\n",
            "|      3|  Kelly| 32|West Sherriside|\n",
            "|      4| Samuel| 60|    East Andrew|\n",
            "|      5|  Tracy| 25|    Ryanchester|\n",
            "+-------+-------+---+---------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Movies:\n",
            "+--------+--------------+------+------------+\n",
            "|movie_id|         title| genre|release_year|\n",
            "+--------+--------------+------+------------+\n",
            "|       1|Process garden|Sci-Fi|        1994|\n",
            "|       2|   Too defense|Action|        2023|\n",
            "|       3|  Detail plant|Action|        1987|\n",
            "|       4|    See couple|Sci-Fi|        1989|\n",
            "|       5|  Front really| Drama|        1984|\n",
            "+--------+--------------+------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Ratings:\n",
            "+-------+--------+------+-------------------+\n",
            "|user_id|movie_id|rating|          timestamp|\n",
            "+-------+--------+------+-------------------+\n",
            "|   9429|    4455|     3|2023-07-20 00:22:09|\n",
            "|   8160|    4172|     1|2022-09-08 23:25:01|\n",
            "|   7927|    4740|     3|2022-01-18 11:55:38|\n",
            "|   4101|    3605|     2|2021-06-15 02:23:06|\n",
            "|   6375|     585|     5|2022-06-20 00:47:19|\n",
            "+-------+--------+------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Watch History:\n",
            "+-------+--------+-------------------+\n",
            "|user_id|movie_id|         watch_time|\n",
            "+-------+--------+-------------------+\n",
            "|   2108|    4263|2022-09-29 06:14:52|\n",
            "|   8420|     963|2021-10-12 02:12:25|\n",
            "|   2598|     474|2024-04-09 02:44:57|\n",
            "|   5287|     434|2022-02-16 15:04:21|\n",
            "|   1417|    4127|2024-01-15 05:26:10|\n",
            "+-------+--------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Search Logs:\n",
            "+-------+--------+-------------------+\n",
            "|user_id| keyword|          timestamp|\n",
            "+-------+--------+-------------------+\n",
            "|    223|thriller|2023-11-02 11:55:55|\n",
            "|   1783|  latest|2022-02-14 22:43:58|\n",
            "|   8557|   drama|2021-04-08 16:10:27|\n",
            "|   1693|  comedy|2022-05-15 10:20:38|\n",
            "|   3167|   anime|2022-02-26 17:54:51|\n",
            "+-------+--------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Netflix Data Cleaning and Preparation with PySpark"
      ],
      "metadata": {
        "id": "TAwwKYJN3Wyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand, when, col\n",
        "\n",
        "# Add a random number column and map to gender\n",
        "users_df = users_df.withColumn(\"random_val\", rand())\n",
        "\n",
        "users_df = users_df.withColumn(\n",
        "    \"gender\",\n",
        "    when(col(\"random_val\") < 0.4, \"Male\")\n",
        "    .when(col(\"random_val\") < 0.8, \"Female\")\n",
        "    .otherwise(\"Other\")\n",
        ").drop(\"random_val\")  # Drop helper column\n"
      ],
      "metadata": {
        "id": "qI7HmjjG3wPH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.printSchema()\n",
        "users_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siVV9R1L4N2y",
        "outputId": "0715023d-f893-4044-ad0f-d239058fc233"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = false)\n",
            " |-- location: string (nullable = true)\n",
            " |-- gender: string (nullable = false)\n",
            "\n",
            "+-------+-------+---+---------------+------+\n",
            "|user_id|   name|age|       location|gender|\n",
            "+-------+-------+---+---------------+------+\n",
            "|      1|  Kevin| 56|  Nicholsonport|Female|\n",
            "|      2|Cassidy| 46|      Josephton|Female|\n",
            "|      3|  Kelly| 32|West Sherriside|Female|\n",
            "|      4| Samuel| 60|    East Andrew| Other|\n",
            "|      5|  Tracy| 25|    Ryanchester|  Male|\n",
            "+-------+-------+---+---------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Step 1: Handle Missing Values\n",
        "# ----------------------------\n",
        "\n",
        "# Fill missing age with average age\n",
        "avg_age = users_df.selectExpr(\"avg(age)\").first()[0]\n",
        "users_df = users_df.fillna({\"age\": int(avg_age)})\n",
        "\n",
        "# Fill missing gender with 'Unknown'\n",
        "users_df = users_df.fillna({\"gender\": \"Unknown\"})\n",
        "\n",
        "# Drop records with missing critical values in watch history or ratings\n",
        "watch_history_df = watch_history_df.dropna(subset=[\"user_id\", \"movie_id\"])\n",
        "ratings_df = ratings_df.dropna(subset=[\"user_id\", \"movie_id\", \"rating\"])"
      ],
      "metadata": {
        "id": "swd44KbU4RiT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Step 2: Data Type Conversions\n",
        "# ----------------------------\n",
        "from pyspark.sql.types import TimestampType\n",
        "# Convert timestamp strings to TimestampType\n",
        "# Rename 'watch_time' to 'timestamp' and convert to TimestampType\n",
        "watch_history_df = watch_history_df \\\n",
        "    .withColumn(\"timestamp\", col(\"watch_time\").cast(TimestampType())) \\\n",
        "    .drop(\"watch_time\")\n",
        "ratings_df = ratings_df.withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType()))\n",
        "search_logs_df = search_logs_df.withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType()))"
      ],
      "metadata": {
        "id": "sPA3PWxn4WLR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize genres into array (if comma-separated)\n",
        "from pyspark.sql.functions import split, col\n",
        "\n",
        "movies_df = movies_df.withColumn(\"primary_genre\", split(col(\"genre\"), \"\\|\")[0])"
      ],
      "metadata": {
        "id": "U99q1PbK442R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUhYq1KZ5WoU",
        "outputId": "bf1c924e-d444-45c2-ef49-26a81539c5e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(movie_id='1', title='Process garden', genre='Sci-Fi', release_year='1994', primary_genre='Sci-Fi'),\n",
              " Row(movie_id='2', title='Too defense', genre='Action', release_year='2023', primary_genre='Action'),\n",
              " Row(movie_id='3', title='Detail plant', genre='Action', release_year='1987', primary_genre='Action'),\n",
              " Row(movie_id='4', title='See couple', genre='Sci-Fi', release_year='1989', primary_genre='Sci-Fi'),\n",
              " Row(movie_id='5', title='Front really', genre='Drama', release_year='1984', primary_genre='Drama')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Step 4: Remove Duplicates\n",
        "# ----------------------------\n",
        "\n",
        "users_df = users_df.dropDuplicates()\n",
        "movies_df = movies_df.dropDuplicates()\n",
        "ratings_df = ratings_df.dropDuplicates()\n",
        "watch_history_df = watch_history_df.dropDuplicates()\n",
        "search_logs_df = search_logs_df.dropDuplicates()"
      ],
      "metadata": {
        "id": "CExTlds15uk6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Step 5: Save Cleaned Data (Optional)\n",
        "# ----------------------------\n",
        "users_df.write.csv(f\"{base_path}/cleaned_users.csv\", header=True, mode=\"overwrite\")\n",
        "movies_df.write.csv(f\"{base_path}/cleaned_movies.csv\", header=True, mode=\"overwrite\")\n",
        "ratings_df.write.csv(f\"{base_path}/cleaned_ratings.csv\", header=True, mode=\"overwrite\")\n",
        "watch_history_df.write.csv(f\"{base_path}/cleaned_watch_history.csv\", header=True, mode=\"overwrite\")\n",
        "search_logs_df.write.csv(f\"{base_path}/cleaned_search_logs.csv\", header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "zZV685s75v0G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Preview Cleaned Data\n",
        "# ----------------------------\n",
        "\n",
        "print(\"Users:\")\n",
        "users_df.show(5)\n",
        "\n",
        "print(\"Movies:\")\n",
        "movies_df.show(5)\n",
        "\n",
        "print(\"Ratings:\")\n",
        "ratings_df.show(5)\n",
        "\n",
        "print(\"Watch History:\")\n",
        "watch_history_df.show(5)\n",
        "\n",
        "print(\"Search Logs:\")\n",
        "search_logs_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjcheGKK5582",
        "outputId": "28d63dbc-c9cb-4d45-cd5f-b3e9da9debf7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users:\n",
            "+-------+--------+---+---------------+------+\n",
            "|user_id|    name|age|       location|gender|\n",
            "+-------+--------+---+---------------+------+\n",
            "|     44|  Steven| 21|    Port Andrew| Other|\n",
            "|     99|  Stacey| 18|Port Nathanstad|Female|\n",
            "|    246|   Bryce| 24|    New Timothy|  Male|\n",
            "|    330|Brittany| 36|   South Steven|Female|\n",
            "|    706| Crystal| 45|      Emmaville|  Male|\n",
            "+-------+--------+---+---------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Movies:\n",
            "+--------+--------------------+-----------+------------+-------------+\n",
            "|movie_id|               title|      genre|release_year|primary_genre|\n",
            "+--------+--------------------+-----------+------------+-------------+\n",
            "|     510|    Guy network wide|Documentary|        2006|  Documentary|\n",
            "|     757|Condition live re...|     Action|        1987|       Action|\n",
            "|    1289|Cultural all best...|    Romance|        1993|      Romance|\n",
            "|    1506|Offer fall genera...|     Action|        1994|       Action|\n",
            "|    1780|                 Age|Documentary|        1992|  Documentary|\n",
            "+--------+--------------------+-----------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Ratings:\n",
            "+-------+--------+------+-------------------+\n",
            "|user_id|movie_id|rating|          timestamp|\n",
            "+-------+--------+------+-------------------+\n",
            "|   3222|    4312|     1|2023-05-30 10:09:57|\n",
            "|   6262|    3899|     3|2021-12-31 00:45:23|\n",
            "|   7612|     629|     5|2021-09-15 00:41:54|\n",
            "|   8679|    3284|     2|2024-06-19 15:34:32|\n",
            "|   5965|    1355|     2|2022-10-28 21:57:50|\n",
            "+-------+--------+------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Watch History:\n",
            "+-------+--------+-------------------+\n",
            "|user_id|movie_id|          timestamp|\n",
            "+-------+--------+-------------------+\n",
            "|   8534|    4151|2024-03-29 13:46:41|\n",
            "|   8867|    1784|2023-02-14 21:50:23|\n",
            "|   4819|     590|2023-04-13 00:28:00|\n",
            "|   7668|    3145|2022-12-05 10:37:53|\n",
            "|   5129|    2054|2024-06-03 17:01:52|\n",
            "+-------+--------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Search Logs:\n",
            "+-------+--------+-------------------+\n",
            "|user_id| keyword|          timestamp|\n",
            "+-------+--------+-------------------+\n",
            "|   8248|  action|2022-08-25 10:50:14|\n",
            "|   1767| classic|2022-07-16 04:15:57|\n",
            "|   1464| classic|2022-03-12 22:31:37|\n",
            "|   3961|   drama|2023-02-01 07:45:13|\n",
            "|    131|thriller|2023-09-12 21:14:00|\n",
            "+-------+--------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "M4tbWmh4_5Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read cleaned datasets\n",
        "users_df = spark.read.csv(f\"{base_path}/cleaned_users.csv\", header=True, inferSchema=True)\n",
        "movies_df = spark.read.csv(f\"{base_path}/cleaned_movies.csv\", header=True, inferSchema=True)\n",
        "watch_history_df = spark.read.csv(f\"{base_path}/cleaned_watch_history.csv\", header=True, inferSchema=True)\n",
        "ratings_df = spark.read.csv(f\"{base_path}/cleaned_ratings.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "dfo_1uBU6LZv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, count, col, split, explode, when, lit, round, concat_ws"
      ],
      "metadata": {
        "id": "-Y4zzwnJ6uiI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Feature 1: Average Rating Per User\n",
        "user_avg_rating_df = ratings_df.groupBy(\"user_id\") \\\n",
        "    .agg(avg(\"rating\").alias(\"avg_user_rating\"))"
      ],
      "metadata": {
        "id": "If56kfG-654p"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Feature 2: Average Rating Per Movie\n",
        "movie_avg_rating_df = ratings_df.groupBy(\"movie_id\") \\\n",
        "    .agg(avg(\"rating\").alias(\"avg_movie_rating\"))\n",
        "\n",
        "# ‚úÖ Feature 3: Total Number of Ratings Per Movie\n",
        "movie_rating_count_df = ratings_df.groupBy(\"movie_id\") \\\n",
        "    .agg(count(\"rating\").alias(\"num_ratings\"))\n",
        "\n",
        "# ‚úÖ Feature 4: Watch Count Per Movie\n",
        "watch_count_df = watch_history_df.groupBy(\"movie_id\") \\\n",
        "    .agg(count(\"timestamp\").alias(\"watch_count\"))\n",
        "\n",
        "# ‚úÖ Feature 5: Explode genres for genre-level aggregation\n",
        "movies_exploded_df = movies_df.withColumn(\"genre_array\", split(col(\"genre\"), \"\\\\|\"))\n",
        "movies_exploded_df = movies_exploded_df.withColumn(\"genre\", explode(col(\"genre_array\")))\n",
        "\n",
        "# ‚úÖ Feature 6: Number of Movies Watched Per User\n",
        "user_watch_count_df = watch_history_df.groupBy(\"user_id\") \\\n",
        "    .agg(count(\"movie_id\").alias(\"movies_watched\"))\n",
        "\n",
        "# ‚úÖ Feature 7: Rating Deviation (difference from movie avg)\n",
        "rating_with_movie_avg = ratings_df.join(movie_avg_rating_df, on=\"movie_id\", how=\"left\")\n",
        "rating_with_movie_avg = rating_with_movie_avg.withColumn(\n",
        "    \"rating_deviation\",\n",
        "    col(\"rating\") - col(\"avg_movie_rating\")\n",
        ")"
      ],
      "metadata": {
        "id": "alsRDd3H7B49"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_exploded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-QQ7CNm8Dsz",
        "outputId": "631b4b81-ddff-4bdb-9213-74662d8b1919"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(movie_id=510, title='Guy network wide', genre='Documentary', release_year=2006, primary_genre='Documentary', genre_array=['Documentary'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Save the engineered features as CSV for downstream processing\n",
        "user_avg_rating_df.write.csv(f\"{base_path}/features/user_avg_rating.csv\", header=True, mode=\"overwrite\")\n",
        "movie_avg_rating_df.write.csv(f\"{base_path}/features/movie_avg_rating.csv\", header=True, mode=\"overwrite\")\n",
        "movie_rating_count_df.write.csv(f\"{base_path}/features/movie_rating_count.csv\", header=True, mode=\"overwrite\")\n",
        "watch_count_df.write.csv(f\"{base_path}/features/movie_watch_count.csv\", header=True, mode=\"overwrite\")\n",
        "user_watch_count_df.write.csv(f\"{base_path}/features/user_watch_count.csv\", header=True, mode=\"overwrite\")\n",
        "rating_with_movie_avg.write.csv(f\"{base_path}/features/rating_with_deviation.csv\", header=True, mode=\"overwrite\")\n",
        "# ‚úÖ Fix array column before CSV write\n",
        "movies_exploded_to_save = movies_exploded_df.withColumn(\"genres_joined\", concat_ws(\"|\", \"genre_array\")) \\\n",
        "                                            .drop(\"genre_array\")\n",
        "movies_exploded_to_save.write.csv(f\"{base_path}/features/movies_exploded_genres.csv\", header=True, mode=\"overwrite\")\n",
        "print(\"‚úÖ Feature Engineering Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBR4m-oD7fFj",
        "outputId": "152fe3b5-d5c9-4838-9324-2fc20db49a0c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature Engineering Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning"
      ],
      "metadata": {
        "id": "XZVb9XTa_-Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç What is ALS (Alternating Least Squares)?\n",
        "# ALS (Alternating Least Squares) is a collaborative filtering algorithm used primarily for recommender systems‚Äîlike Netflix, Amazon, Spotify, etc.\n",
        "\n",
        "# üìå ALS in Simple Terms:\n",
        "# ALS works by trying to learn latent factors for users and items (e.g., movies), so it can predict how likely a user is to like a particular item they haven‚Äôt interacted with yet.\n",
        "# ‚úÖ Prepare Dataset for ALS Model\n",
        "# We'll use the rating_with_deviation_df for training ALS\n",
        "# ‚úÖ Load Feature Data\n",
        "user_watch_count_df = spark.read.csv(f\"{base_path}/features/user_watch_count.csv\", header=True, inferSchema=True)\n",
        "rating_with_deviation_df = spark.read.csv(f\"{base_path}/features/rating_with_deviation.csv\", header=True, inferSchema=True)\n",
        "movies_exploded_genres_df = spark.read.csv(f\"{base_path}/features/movies_exploded_genres.csv\", header=True, inferSchema=True)\n",
        "\n",
        "print(\"‚úÖ Feature datasets loaded\")\n",
        "\n",
        "als_df = rating_with_deviation_df.select(\n",
        "    col(\"user_id\").cast(\"integer\"),\n",
        "    col(\"movie_id\").cast(\"integer\"),\n",
        "    col(\"rating\").cast(\"float\")\n",
        ").dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVyfiIj689r8",
        "outputId": "c0e00b3b-4435-4e5e-8b1f-aa9ec68167d1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature datasets loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Train-Test Split\n",
        "(training_data, test_data) = als_df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "S-GOxVRP9yQ_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ ALS Model\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "als = ALS(\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    userCol=\"user_id\",\n",
        "    itemCol=\"movie_id\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True\n",
        ")"
      ],
      "metadata": {
        "id": "RM0GrH3i95pr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = als.fit(training_data)\n",
        "print(\"‚úÖ ALS model trained\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UHQ2TZn-FDc",
        "outputId": "1427888d-8c8b-419e-cf39-9fc910ffa17a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ALS model trained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Evaluate Model\n",
        "predictions = model.transform(test_data)\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"‚úÖ Root-mean-square error = {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18fil3J--Ihy",
        "outputId": "5805d918-8712-477f-847d-a84e55625764"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Root-mean-square error = 1.7602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Save model if needed\n",
        "model.save(f\"{base_path}/models/als_model\")\n",
        "\n",
        "print(\"üéâ Model training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "itElHPxx-mSA",
        "outputId": "a18f5f50-2c3f-4a03-b7ab-a336f4722fc3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o767.save.\n: java.io.IOException: Path /content/models/als_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-58-119051173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ‚úÖ Save model if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{base_path}/models/als_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üéâ Model training complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;34m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a string, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"JavaMLWriter\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o767.save.\n: java.io.IOException: Path /content/models/als_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "from pyspark.ml.recommendation import ALSModel\n",
        "\n",
        "# ‚úÖ Load trained ALS model\n",
        "als_model = ALSModel.load(f\"{base_path}/models/als_model\")\n",
        "\n",
        "\n",
        "# ‚úÖ Generate top 10 recommendations for each user\n",
        "user_recommendations_df = als_model.recommendForAllUsers(10)\n",
        "\n",
        "# ‚úÖ Flatten the nested 'recommendations' column\n",
        "recommendations_flat_df = user_recommendations_df \\\n",
        "    .withColumn(\"rec\", explode(\"recommendations\")) \\\n",
        "    .select(\n",
        "        col(\"user_id\"),\n",
        "        col(\"rec.movie_id\").alias(\"movie_id\"),\n",
        "        col(\"rec.rating\").alias(\"predicted_rating\")\n",
        "    )\n",
        "\n",
        "# ‚úÖ Save as CSV\n",
        "recommendations_flat_df.write.csv(f\"{base_path}/model/recommendations.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "print(\"‚úÖ Recommendations file written to /model/recommendations.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDwAtJogBN4L",
        "outputId": "a1c2e9f2-03ff-4a7b-fb8e-b2771aad5144"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Recommendations file written to /model/recommendations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Model Preparation & Export"
      ],
      "metadata": {
        "id": "HAa6TmfKADi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÇ Load Cleaned and Feature Data\n",
        "users_df = spark.read.csv(f\"{base_path}/cleaned_users.csv\", header=True, inferSchema=True)\n",
        "movies_df = spark.read.csv(f\"{base_path}/cleaned_movies.csv\", header=True, inferSchema=True)\n",
        "ratings_df = spark.read.csv(f\"{base_path}/cleaned_ratings.csv\", header=True, inferSchema=True)\n",
        "recommendations_df = spark.read.csv(f\"{base_path}/model/recommendations.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "uI8LbqwZ-9jx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOL5oZs4B9t6",
        "outputId": "236826e5-f5fd-4df6-bfb6-710b9c21e6fa"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id=1, movie_id=1194, predicted_rating=5.8309617),\n",
              " Row(user_id=1, movie_id=221, predicted_rating=5.8091965),\n",
              " Row(user_id=1, movie_id=4156, predicted_rating=5.7953186),\n",
              " Row(user_id=1, movie_id=4122, predicted_rating=5.7914705),\n",
              " Row(user_id=1, movie_id=4810, predicted_rating=5.7662034)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Feature Files\n",
        "user_watch_count_df = spark.read.csv(f\"{base_path}/features/user_watch_count.csv\", header=True, inferSchema=True)\n",
        "rating_with_deviation_df = spark.read.csv(f\"{base_path}/features/rating_with_deviation.csv\", header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "D7JSFhEcCJbE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Join & Prepare Final Data Model\n",
        "final_model_df = recommendations_df \\\n",
        "    .join(users_df, on=\"user_id\", how=\"left\") \\\n",
        "    .join(movies_df, on=\"movie_id\", how=\"left\") \\\n",
        "    .join(user_watch_count_df, on=\"user_id\", how=\"left\") \\\n",
        "    .join(rating_with_deviation_df, on=[\"user_id\", \"movie_id\"], how=\"left\")\n"
      ],
      "metadata": {
        "id": "162iO3pBCPoM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e219IzX4CSI_",
        "outputId": "20b24010-2928-48e8-d441-f53442fddb5f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id=1, movie_id=1194, predicted_rating=5.8309617, name='Kevin', age=56, location='Nicholsonport', gender='Female', title='Company young', genre='Comedy', release_year=2002, primary_genre='Comedy', movies_watched=9, rating=None, timestamp=None, avg_movie_rating=None, rating_deviation=None),\n",
              " Row(user_id=1, movie_id=221, predicted_rating=5.8091965, name='Kevin', age=56, location='Nicholsonport', gender='Female', title='Report remain miss', genre='Action', release_year=1980, primary_genre='Action', movies_watched=9, rating=None, timestamp=None, avg_movie_rating=None, rating_deviation=None),\n",
              " Row(user_id=1, movie_id=4156, predicted_rating=5.7953186, name='Kevin', age=56, location='Nicholsonport', gender='Female', title='Ground loss', genre='Romance', release_year=1988, primary_genre='Romance', movies_watched=9, rating=None, timestamp=None, avg_movie_rating=None, rating_deviation=None),\n",
              " Row(user_id=1, movie_id=4122, predicted_rating=5.7914705, name='Kevin', age=56, location='Nicholsonport', gender='Female', title='Minute positive outside yet', genre='Drama', release_year=1990, primary_genre='Drama', movies_watched=9, rating=None, timestamp=None, avg_movie_rating=None, rating_deviation=None),\n",
              " Row(user_id=1, movie_id=4810, predicted_rating=5.7662034, name='Kevin', age=56, location='Nicholsonport', gender='Female', title='Southern', genre='Action', release_year=2015, primary_genre='Action', movies_watched=9, rating=None, timestamp=None, avg_movie_rating=None, rating_deviation=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Reorder & Select Columns for Export\n",
        "# ‚úÖ Reorder & Select Columns for Export\n",
        "export_df = final_model_df.select(\n",
        "    \"user_id\", \"name\", \"age\", \"gender\", \"location\",\n",
        "    \"movie_id\", \"title\", \"genre\", \"release_year\",\n",
        "    \"predicted_rating\", \"avg_movie_rating\", \"rating_deviation\", \"movies_watched\"\n",
        ")\n",
        "# üìÜ Save to CSV for Power BI or Front-End Ingestion\n",
        "export_path = f\"{base_path}/export/final_recommendation_model.csv\"\n",
        "export_df.write.csv(export_path, header=True, mode=\"overwrite\")\n",
        "\n",
        "print(\"‚úÖ Data model exported successfully to:\", export_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u75WqJbCa9h",
        "outputId": "edc6b2e5-ce98-4939-ea41-15f1686b14ed"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data model exported successfully to: /content/export/final_recommendation_model.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSBEebmYC8pk",
        "outputId": "337a6bee-4d16-4010-8fd5-47a27d224d19"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id=1, name='Kevin', age=56, gender='Female', location='Nicholsonport', movie_id=1194, title='Company young', genre='Comedy', release_year=2002, predicted_rating=5.8309617, avg_movie_rating=None, rating_deviation=None, movies_watched=9),\n",
              " Row(user_id=1, name='Kevin', age=56, gender='Female', location='Nicholsonport', movie_id=221, title='Report remain miss', genre='Action', release_year=1980, predicted_rating=5.8091965, avg_movie_rating=None, rating_deviation=None, movies_watched=9),\n",
              " Row(user_id=1, name='Kevin', age=56, gender='Female', location='Nicholsonport', movie_id=4156, title='Ground loss', genre='Romance', release_year=1988, predicted_rating=5.7953186, avg_movie_rating=None, rating_deviation=None, movies_watched=9),\n",
              " Row(user_id=1, name='Kevin', age=56, gender='Female', location='Nicholsonport', movie_id=4122, title='Minute positive outside yet', genre='Drama', release_year=1990, predicted_rating=5.7914705, avg_movie_rating=None, rating_deviation=None, movies_watched=9),\n",
              " Row(user_id=1, name='Kevin', age=56, gender='Female', location='Nicholsonport', movie_id=4810, title='Southern', genre='Action', release_year=2015, predicted_rating=5.7662034, avg_movie_rating=None, rating_deviation=None, movies_watched=9)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power BI / Dashboard Integration Preparation"
      ],
      "metadata": {
        "id": "cJWrZof3DylV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÇ Load Exported Recommendation Data\n",
        "export_path = \"/content/export/final_recommendation_model.csv\"\n",
        "dashboard_df = spark.read.csv(export_path, header=True, inferSchema=True)\n",
        "\n",
        "# ‚úÖ Perform Sample Aggregations for Dashboard\n",
        "from pyspark.sql.functions import avg, countDistinct\n",
        "\n",
        "# üéØ Average predicted rating per genre\n",
        "genre_avg_df = dashboard_df.groupBy(\"genre\").agg(avg(\"predicted_rating\").alias(\"avg_predicted_rating\"))\n",
        "\n",
        "# üë• Top 10 most active users (by movies_watched)\n",
        "top_users_df = dashboard_df.select(\"user_id\", \"name\", \"movies_watched\") \\\n",
        "    .dropDuplicates([\"user_id\"]) \\\n",
        "    .orderBy(\"movies_watched\", ascending=False) \\\n",
        "    .limit(10)\n",
        "\n",
        "# üé¨ Top 10 recommended movies (highest predicted rating)\n",
        "top_movies_df = dashboard_df.select(\"movie_id\", \"title\", \"predicted_rating\") \\\n",
        "    .orderBy(\"predicted_rating\", ascending=False) \\\n",
        "    .limit(10)\n",
        "\n",
        "# üåç Distribution by location\n",
        "location_distribution_df = dashboard_df.groupBy(\"location\").agg(countDistinct(\"user_id\").alias(\"unique_users\"))\n",
        "\n",
        "# üìÅ Export Aggregations for Dashboard\n",
        "genre_avg_df.write.csv(\"/content/export/dashboard_genre_avg.csv\", header=True, mode=\"overwrite\")\n",
        "top_users_df.write.csv(\"/content/export/dashboard_top_users.csv\", header=True, mode=\"overwrite\")\n",
        "top_movies_df.write.csv(\"/content/export/dashboard_top_movies.csv\", header=True, mode=\"overwrite\")\n",
        "location_distribution_df.write.csv(\"/content/export/dashboard_location_distribution.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "print(\"‚úÖ Dashboard data files exported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUCT2Vt3DEX5",
        "outputId": "e5b67556-72e7-4658-c53a-b230b95cb8fc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dashboard data files exported successfully.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}